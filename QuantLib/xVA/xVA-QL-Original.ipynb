{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f4bfed",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/matlogica/AADC-Python/blob/main/QuantLib/xVA/xVA-QL-Original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6546d75-18b9-4dae-8222-a1ca3e8cb95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: QuantLib in /home/dimach/projects2/AADC-Python/.venv/lib/python3.11/site-packages (1.34)\n"
     ]
    }
   ],
   "source": [
    "!pip install QuantLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7761c307-5abe-4d19-abde-87b2e7a43854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimach/projects2/AADC-Python/.venv/lib/python3.11/site-packages/QuantLib/QuantLib.py:30000: FutureWarning: setEvaluationDate is deprecated; use evaluationDate\n",
      "  return _QuantLib.Settings_setEvaluationDate(self, d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.5282798805582\n",
      "xVa pricing time  35.7695097620599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "##!python\n",
    "## -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This Python module calculates the Credit Value Adjustment for a single netting set of plain vanilla\n",
    "interest rate swaps.\n",
    "\n",
    "The code is based on the IPython Notebook of Matthias Groncki (see reference below).\n",
    "\n",
    "References:\n",
    "\n",
    "\"CVA Calculation with QuantLib and Python\", Matthias Groncki\n",
    "    - https://ipythonquant.wordpress.com/tag/cva/\n",
    "    - http://nbviewer.ipython.org/github/mgroncki/IPythonScripts/blob/master/CVA_calculation_I.ipynb\n",
    "\n",
    "\"FOOLING AROUND WITH QUANTLIB: GSR MODEL\", Peter Caspers:\n",
    "    - https://quantlib.wordpress.com/tag/gsr-model/\n",
    "\n",
    "\"One Factor Gaussian Short Rate Model Implementation\", Peter Caspers, March 1, 2013:\n",
    "    - http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2246013\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# TODO PyTorch tensors, data sets, data loader and samplers, deep modeling with torch.nn...\n",
    "\n",
    "from time import perf_counter as pc\n",
    "import numpy as np\n",
    "#import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Check version of QuantLib...\n",
    "import QuantLib as ql\n",
    "\n",
    "\n",
    "def get_version():\n",
    "    return list(map(int, ql.__version__.split('.')))\n",
    "\n",
    "\n",
    "if get_version()[1] < 6:\n",
    "    print('You need QuantLib version 1.6 or higher!')\n",
    "    exit()\n",
    "\n",
    "# General QuantLib functions...\n",
    "set_evaluation_date = lambda date: ql.Settings.instance().setEvaluationDate(date)\n",
    "\n",
    "link_to_curve = lambda relinkable_handle, curve: relinkable_handle.linkTo(curve)\n",
    "\n",
    "\n",
    "# Random numbers...\n",
    "def create_random_number_generator(evaluation_time_grid, seed=1):\n",
    "\n",
    "    uniform_rng = ql.MersenneTwisterUniformRng(seed)\n",
    "    uniform_rsg = ql.MersenneTwisterUniformRsg(len(evaluation_time_grid) - 1, uniform_rng)\n",
    "\n",
    "    return ql.InvCumulativeMersenneTwisterGaussianRsg(uniform_rsg)\n",
    "\n",
    "\n",
    "# Default curve...\n",
    "def create_default_curve(default_dates, hazard_rates, day_count=ql.Actual365Fixed()):\n",
    "\n",
    "    default_curve = ql.HazardRateCurve(default_dates, hazard_rates, day_count)\n",
    "    default_curve.enableExtrapolation()\n",
    "\n",
    "    return default_curve\n",
    "\n",
    "\n",
    "def get_default_probability(times, default_curve):\n",
    "\n",
    "    # TODO ...\n",
    "    # torch.FloatTensor(default_curve.defaultProbability)\n",
    "\n",
    "    return np.vectorize(default_curve.defaultProbability)(times)\n",
    "\n",
    "\n",
    "def get_survival_probability(times, default_curve):\n",
    "    return np.vectorize(default_curve.survivalProbability)(times)\n",
    "\n",
    "\n",
    "def get_default_density(times, default_curve):\n",
    "    return np.vectorize(default_curve.defaultDensity)(times)\n",
    "\n",
    "\n",
    "def get_hazard_rate(times, default_curve):\n",
    "    \"\"\"\n",
    "\n",
    "    @param times:\n",
    "    @param default_curve:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "\n",
    "    return np.vectorize(default_curve.hazardRate)(times)\n",
    "\n",
    "\n",
    "def calculate_default_probability_grid(evaluation_time_grid, default_curve):\n",
    "    return np.vectorize(default_curve.defaultProbability)(\n",
    "        evaluation_time_grid[:-1], evaluation_time_grid[1:]\n",
    "    )\n",
    "\n",
    "\n",
    "# Discount curve...\n",
    "def create_flat_forward(todays_date, rate, day_count=ql.Actual365Fixed()):\n",
    "\n",
    "    flat_forward = ql.FlatForward(todays_date, ql.QuoteHandle(rate), day_count)\n",
    "    flat_forward.enableExtrapolation()\n",
    "\n",
    "    return flat_forward, \\\n",
    "           ql.YieldTermStructureHandle(flat_forward), \\\n",
    "           ql.RelinkableYieldTermStructureHandle(flat_forward)\n",
    "\n",
    "\n",
    "def generate_discount_factors(flat_forward_handle, evaluation_time_grid):\n",
    "    return np.vectorize(flat_forward_handle.discount)(evaluation_time_grid)\n",
    "\n",
    "\n",
    "def get_discount_curve(curve_dates,\n",
    "                       discount_factors,\n",
    "                       day_count_convention=ql.Actual365Fixed()):\n",
    "\n",
    "    discount_curve = ql.DiscountCurve(\n",
    "        curve_dates,\n",
    "        discount_factors,\n",
    "        day_count_convention\n",
    "    )\n",
    "\n",
    "    discount_curve.enableExtrapolation()\n",
    "\n",
    "    return discount_curve\n",
    "\n",
    "\n",
    "# Pricing engine...\n",
    "def create_pricing_engine(flat_forward_relinkable_handle):\n",
    "    return ql.DiscountingSwapEngine(flat_forward_relinkable_handle)\n",
    "\n",
    "\n",
    "# Swap portfolio...\n",
    "def create_plain_vanilla_swap(start_date, maturity_date,\n",
    "                              nominal_amount,\n",
    "                              float_index,\n",
    "                              fixed_rate,\n",
    "                              fixed_leg_tenor=ql.Period(\"1y\"),\n",
    "                              fixed_leg_business_day_convention=ql.ModifiedFollowing,\n",
    "                              fixed_leg_day_count_convention=ql.Thirty360(ql.Thirty360.BondBasis),\n",
    "                              calendar=ql.Sweden(),\n",
    "                              spread=0.0,\n",
    "                              swap_type=ql.VanillaSwap.Payer):\n",
    "\n",
    "    end_date = calendar.advance(start_date, maturity_date)\n",
    "\n",
    "    fixed_schedule = ql.Schedule(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        fixed_leg_tenor,\n",
    "        float_index.fixingCalendar(),\n",
    "        fixed_leg_business_day_convention,\n",
    "        fixed_leg_business_day_convention,\n",
    "        ql.DateGeneration.Backward,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    float_schedule = ql.Schedule(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        float_index.tenor(),\n",
    "        float_index.fixingCalendar(),\n",
    "        float_index.businessDayConvention(),\n",
    "        float_index.businessDayConvention(),\n",
    "        ql.DateGeneration.Backward,\n",
    "        False\n",
    "    )\n",
    "\n",
    "    swap = ql.VanillaSwap(\n",
    "        swap_type,\n",
    "        nominal_amount,\n",
    "        fixed_schedule,\n",
    "        fixed_rate,\n",
    "        fixed_leg_day_count_convention,\n",
    "        float_schedule,\n",
    "        float_index,\n",
    "        spread,\n",
    "        float_index.dayCounter()\n",
    "    )\n",
    "\n",
    "    return swap, [float_index.fixingDate(x) for x in float_schedule][:-1]\n",
    "\n",
    "\n",
    "def make_simple_portfolio(list_of_start_dates, list_of_maturity_dates,\n",
    "                          list_of_nominal_amounts,\n",
    "                          list_of_float_indices,\n",
    "                          list_of_fixed_rates,\n",
    "                          list_of_swap_types):\n",
    "\n",
    "    simple_portfolio = []\n",
    "\n",
    "    for (start_date, maturity_date,\n",
    "         nominal_amount,\n",
    "         float_index,\n",
    "         fixed_rate,\n",
    "         swap_type) in zip(list_of_start_dates, list_of_maturity_dates,\n",
    "                           list_of_nominal_amounts,\n",
    "                           list_of_float_indices,\n",
    "                           list_of_fixed_rates,\n",
    "                           list_of_swap_types):\n",
    "\n",
    "        simple_portfolio.append(\n",
    "            create_plain_vanilla_swap(start_date, maturity_date,\n",
    "                                      nominal_amount,\n",
    "                                      float_index,\n",
    "                                      fixed_rate,\n",
    "                                      swap_type=swap_type)\n",
    "        )\n",
    "\n",
    "    return simple_portfolio\n",
    "\n",
    "\n",
    "def calculate_portfolio_npv(flat_forward_relinkable_handle, portfolio):\n",
    "\n",
    "    engine = create_pricing_engine(flat_forward_relinkable_handle)\n",
    "\n",
    "    portfolio_npv = []\n",
    "    for deal, _ in portfolio:\n",
    "        deal.setPricingEngine(engine)\n",
    "        portfolio_npv.append(deal.NPV())\n",
    "\n",
    "    return portfolio_npv\n",
    "\n",
    "\n",
    "# Evaluation grid, curve dates, and NPV matrix...\n",
    "def define_evaluation_grid(todays_date, simple_portfolio, number_of_months=12*6):\n",
    "\n",
    "    evaluation_dates_grid = [\n",
    "        todays_date + ql.Period(i_month, ql.Months) for i_month in range(number_of_months)\n",
    "        ]\n",
    "\n",
    "    for deal in simple_portfolio:\n",
    "        evaluation_dates_grid += deal[1]\n",
    "\n",
    "    evaluation_dates_grid = np.unique(np.sort(evaluation_dates_grid))\n",
    "\n",
    "    evaluation_time_grid = np.vectorize(\n",
    "        lambda x: ql.ActualActual(ql.ActualActual.ISDA).yearFraction(todays_date, x)\n",
    "    )(evaluation_dates_grid)\n",
    "\n",
    "    # diff_evaluation_time_grid = evaluation_time_grid[1:] - evaluation_time_grid[:-1]\n",
    "\n",
    "    return evaluation_dates_grid, evaluation_time_grid  #, diff_evaluation_time_grid\n",
    "\n",
    "\n",
    "def define_curve_dates(date, n_years=10):\n",
    "\n",
    "    # append first half year to date\n",
    "    curve_dates = [date, date + ql.Period(6, ql.Months)]\n",
    "\n",
    "    curve_dates += [date + ql.Period(i_year, ql.Years) for i_year in range(1, n_years + 1)]\n",
    "\n",
    "    return curve_dates\n",
    "\n",
    "\n",
    "# TODO ...\n",
    "def create_npv_matrix(todays_date,\n",
    "                      number_of_paths,\n",
    "                      evaluation_dates_grid,\n",
    "                      simple_portfolio,\n",
    "                      flat_forward,\n",
    "                      flat_forward_relinkable_handle,\n",
    "                      zero_bonds,\n",
    "                      float_index):\n",
    "\n",
    "    n_dates, n_deals = len(evaluation_dates_grid), len(simple_portfolio)\n",
    "\n",
    "    npv_matrix = np.zeros(\n",
    "        (number_of_paths, n_dates, n_deals)\n",
    "    )\n",
    "\n",
    "    for i_path in range(number_of_paths):\n",
    "        for i_date in range(n_dates):\n",
    "\n",
    "            date = evaluation_dates_grid[i_date]\n",
    "\n",
    "            discount_curve = get_discount_curve(\n",
    "                define_curve_dates(date), zero_bonds[i_path, i_date, :]\n",
    "            )\n",
    "\n",
    "            set_evaluation_date(date)\n",
    "            link_to_curve(flat_forward_relinkable_handle, discount_curve)\n",
    "\n",
    "            # TODO Check... is this correct?\n",
    "            is_valid_fixing_date = float_index.isValidFixingDate(date)\n",
    "\n",
    "            if is_valid_fixing_date:\n",
    "                fixing = float_index.fixing(date)\n",
    "                float_index.addFixing(date, fixing)\n",
    "\n",
    "            for i_deal in range(n_deals):\n",
    "                npv_matrix[i_path, i_date, i_deal] = simple_portfolio[i_deal][0].NPV()\n",
    "\n",
    "        ql.IndexManager.instance().clearHistories()\n",
    "\n",
    "    set_evaluation_date(todays_date)\n",
    "    link_to_curve(flat_forward_relinkable_handle, flat_forward)\n",
    "\n",
    "    return npv_matrix\n",
    "\n",
    "\n",
    "def calculate_discounted_npv_matrix(npv_matrix, discount_factors):\n",
    "\n",
    "    discounted_npv_matrix = np.zeros(npv_matrix.shape)\n",
    "\n",
    "    for i in range(npv_matrix.shape[2]):\n",
    "        discounted_npv_matrix[:, :, i] = npv_matrix[:, :, i] * discount_factors\n",
    "\n",
    "    return discounted_npv_matrix\n",
    "\n",
    "\n",
    "# Gsr model and simulation of paths...\n",
    "def generate_gsr_model(flat_forward_handle,\n",
    "                       volatility_step_dates, volatilities,\n",
    "                       mean_reversion,\n",
    "                       forward_measure_time=16.0):\n",
    "\n",
    "    return ql.Gsr(flat_forward_handle,\n",
    "                  volatility_step_dates, volatilities,\n",
    "                  mean_reversion,\n",
    "                  forward_measure_time)\n",
    "\n",
    "\n",
    "def generate_paths(number_of_paths,\n",
    "                   evaluation_time_grid,\n",
    "                   tenors,\n",
    "                   inv_cumulative_gaussian_rsg,\n",
    "                   model):\n",
    "\n",
    "    n_tenors = len(tenors)\n",
    "\n",
    "    diff_evaluation_time_grid = evaluation_time_grid[1:] - evaluation_time_grid[:-1]\n",
    "\n",
    "    x = np.zeros((number_of_paths, len(evaluation_time_grid)))\n",
    "    y = np.zeros((number_of_paths, len(evaluation_time_grid)))\n",
    "\n",
    "    zero_bonds = np.zeros(\n",
    "        (number_of_paths, len(evaluation_time_grid), n_tenors)\n",
    "    )\n",
    "\n",
    "    for j_tenor in range(n_tenors):\n",
    "        zero_bonds[:, 0, j_tenor] = model.zerobond(\n",
    "            tenors[j_tenor], 0, 0\n",
    "        )\n",
    "\n",
    "    process = model.stateProcess()\n",
    "\n",
    "    for n_path in range(number_of_paths):\n",
    "\n",
    "        next_sequence = inv_cumulative_gaussian_rsg.nextSequence().value()\n",
    "\n",
    "        for i_time in range(1, len(evaluation_time_grid)):\n",
    "\n",
    "            t_start = evaluation_time_grid[i_time - 1]\n",
    "            t_end = evaluation_time_grid[i_time]\n",
    "\n",
    "            x[n_path, i_time] = process.expectation(\n",
    "                t_start, x[n_path, i_time - 1], diff_evaluation_time_grid[i_time - 1]\n",
    "            ) + next_sequence[i_time-1] * process.stdDeviation(\n",
    "                t_start, x[n_path, i_time - 1], diff_evaluation_time_grid[i_time - 1]\n",
    "            )\n",
    "\n",
    "            # y equals standardized x (see Gsr-paper by Caspers and Gsr model in QuantLib)\n",
    "            y[n_path, i_time] = \\\n",
    "                (x[n_path, i_time] - process.expectation(0, 0, t_end)) / process.stdDeviation(0, 0, t_end)\n",
    "\n",
    "            for j_tenor in range(n_tenors):\n",
    "                zero_bonds[n_path, i_time, j_tenor] = model.zerobond(\n",
    "                    t_end + tenors[j_tenor], t_end, y[n_path, i_time]\n",
    "                )\n",
    "\n",
    "    return x, zero_bonds\n",
    "\n",
    "\n",
    "# Netting, exposure, and CVA...\n",
    "def calculate_netted_npv_matrix(npv_matrix):\n",
    "    return np.sum(npv_matrix, axis=2)\n",
    "\n",
    "\n",
    "def calculate_exposure(portfolio_npv):\n",
    "\n",
    "    exposure = portfolio_npv.copy()\n",
    "    exposure[exposure < 0] = 0\n",
    "\n",
    "    return exposure\n",
    "\n",
    "\n",
    "def calculate_expected_exposure(portfolio_npv, number_of_paths):\n",
    "    return np.sum(\n",
    "        calculate_exposure(portfolio_npv), axis=0\n",
    "    ) / number_of_paths\n",
    "\n",
    "\n",
    "def calculate_potential_future_exposure(exposure, number_of_paths, quantile=0.95):\n",
    "\n",
    "    # TODO Should we have ceil here?\n",
    "    potential_future_exposure = np.apply_along_axis(\n",
    "        lambda x: np.sort(x)[int(np.ceil(quantile * number_of_paths))], 0, exposure\n",
    "    )\n",
    "\n",
    "    # Alternative formulation: use max of each exposure path\n",
    "    # potential_future_exposure = np.sort(np.max(exposure, axis=1))[quantile * number_of_paths]\n",
    "\n",
    "    return potential_future_exposure\n",
    "\n",
    "\n",
    "def calculate_economic_cva(expected_discounted_exposure, default_probabilities, recovery_rate=0.4):\n",
    "    return (1 - recovery_rate) * np.sum(\n",
    "        expected_discounted_exposure[1:] * default_probabilities\n",
    "    )\n",
    "\n",
    "\n",
    "# Plotting functions...\n",
    "\n",
    "# def plot_npv_paths(n_first, n_last,\n",
    "#                    evaluation_time_grid,\n",
    "#                    portfolio_npv, discounted_portfolio_npv):\n",
    "#\n",
    "#     _, (axis_1, axis_2) = plt.subplots(2, 1, figsize=(12, 10), sharey=True)\n",
    "#\n",
    "#     for i_path in range(n_first, n_last):\n",
    "#         axis_1.plot(evaluation_time_grid, portfolio_npv[i_path, :])\n",
    "#\n",
    "#     axis_1.set_xlabel(\"Years\")\n",
    "#     axis_1.set_ylabel(\"Portfolio NPV\")\n",
    "#     axis_1.set_title(\"Portfolio NPV paths\")\n",
    "#\n",
    "#     for i_path in range(n_first, n_last):\n",
    "#         axis_2.plot(evaluation_time_grid, discounted_portfolio_npv[i_path, :])\n",
    "#\n",
    "#     axis_2.set_xlabel(\"Years\")\n",
    "#     axis_2.set_ylabel(\"Discounted Portfolio NPV\")\n",
    "#     axis_2.set_title(\"Discounted portfolio NPV paths\")\n",
    "#\n",
    "#\n",
    "# def plot_exposure_paths(n_first, n_last,\n",
    "#                         evaluation_time_grid,\n",
    "#                         exposure, discounted_exposure):\n",
    "#\n",
    "#     _, (axis_1, axis_2) = plt.subplots(2, 1, figsize=(12, 10))  # , sharey=True)\n",
    "#\n",
    "#     for i_path in range(n_first, n_last):\n",
    "#         axis_1.plot(evaluation_time_grid, exposure[i_path, :])\n",
    "#\n",
    "#     axis_1.set_ylim([-10000, 70000])\n",
    "#     axis_1.set_xlabel(\"Years\")\n",
    "#     axis_1.set_ylabel(\"Exposure\")\n",
    "#     axis_1.set_title(\"Exposure paths\")\n",
    "#\n",
    "#     for i_path in range(n_first, n_last):\n",
    "#         axis_2.plot(evaluation_time_grid, discounted_exposure[i_path, :])\n",
    "#\n",
    "#     axis_2.set_ylim([-10000, 70000])\n",
    "#     axis_2.set_xlabel(\"Years\")\n",
    "#     axis_2.set_ylabel(\"Discounted Exposure\")\n",
    "#     axis_2.set_title(\"Discounted exposure paths\")\n",
    "#\n",
    "#\n",
    "# def plot_expected_exposure_paths(evaluation_time_grid,\n",
    "#                                  expected_exposure, expected_discounted_exposure):\n",
    "#\n",
    "#     _, (axis_1, axis_2) = plt.subplots(2, 1, figsize=(8, 10))  # , sharey=True)\n",
    "#\n",
    "#     axis_1.plot(evaluation_time_grid, expected_exposure)\n",
    "#\n",
    "#     axis_1.set_xlabel(\"Time in years\")\n",
    "#     axis_1.set_ylabel(\"Exposure\")\n",
    "#     axis_1.set_title(\"Expected exposure\")\n",
    "#\n",
    "#     axis_2.plot(evaluation_time_grid, expected_discounted_exposure)\n",
    "#\n",
    "#     axis_2.set_xlabel(\"Time in years\")\n",
    "#     axis_2.set_ylabel(\"Discounted Exposure\")\n",
    "#     axis_2.set_title(\"Expected discounted exposure\")\n",
    "#\n",
    "#\n",
    "# def plot_expected_discounted_exposure(evaluation_time_grid,\n",
    "#                                       expected_discounted_exposure):\n",
    "#\n",
    "#     # plt.figure(figsize=(7, 5), dpi=300)\n",
    "#     plt.figure()\n",
    "#     plt.plot(evaluation_time_grid, expected_discounted_exposure)\n",
    "#\n",
    "#     plt.ylim([-2000, 10000])\n",
    "#     plt.xlabel(\"Years\")\n",
    "#     plt.ylabel(\"Expected discounted exposure\")\n",
    "#     plt.title(\"Expected discounted exposure\")\n",
    "#\n",
    "#\n",
    "# def plot_potential_future_exposure(evaluation_time_grid,\n",
    "#                                    potential_future_exposure):\n",
    "#\n",
    "#     # plt.figure(figsize=(7, 5), dpi=300)\n",
    "#     plt.figure()\n",
    "#     plt.plot(evaluation_time_grid, potential_future_exposure)\n",
    "#\n",
    "#     plt.xlabel(\"Years\")\n",
    "#     plt.ylabel(\"Potential future exposure\")\n",
    "#     plt.ylim([-2000, 35000])\n",
    "#\n",
    "#     plt.title(\"Potential future exposure\")\n",
    "#\n",
    "#\n",
    "# def plot_default_curve(times, default_curve):\n",
    "#\n",
    "#     _, ((axis_1, axis_2), (axis_3, axis_4)) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "#\n",
    "#     default_probability = get_default_probability(times, default_curve)\n",
    "#\n",
    "#     axis_1.plot(times, default_probability)\n",
    "#\n",
    "#     axis_1.set_xlabel(\"Years\")\n",
    "#     axis_1.set_ylabel(\"Probability\")\n",
    "#     axis_1.set_title(\"Default probability\")\n",
    "#\n",
    "#     survival_probability = get_survival_probability(times, default_curve)\n",
    "#\n",
    "#     axis_2.plot(times, survival_probability)\n",
    "#\n",
    "#     axis_2.set_xlabel(\"Years\")\n",
    "#     axis_2.set_ylabel(\"Probability\")\n",
    "#     axis_2.set_title(\"Survival probability\")\n",
    "#\n",
    "#     default_density = get_default_density(times, default_curve)\n",
    "#\n",
    "#     axis_3.plot(times, default_density)\n",
    "#\n",
    "#     axis_3.set_xlabel(\"Years\")\n",
    "#     axis_3.set_ylabel(\"Density\")\n",
    "#     axis_3.set_title(\"Default density\")\n",
    "#\n",
    "#     hazard_rate = get_hazard_rate(times, default_curve)\n",
    "#\n",
    "#     axis_4.plot(times, hazard_rate)\n",
    "#\n",
    "#     axis_4.set_xlabel(\"Years\")\n",
    "#     axis_4.set_ylabel(\"Rate\")\n",
    "#     axis_4.set_title(\"Hazard rate\")\n",
    "#\n",
    "#\n",
    "def main():\n",
    "\n",
    "    # Set evaluation date...\n",
    "    # todays_date = ql.Date(7, 4, 2015)\n",
    "    todays_date = ql.Date(13, 8, 2015)\n",
    "    # ql.Settings.instance().setEvaluationDate(todays_date)\n",
    "    set_evaluation_date(todays_date)\n",
    "\n",
    "    # Market data...\n",
    "    rate = ql.SimpleQuote(0.03)\n",
    "\n",
    "    flat_forward, flat_forward_handle, flat_forward_relinkable_handle = \\\n",
    "        create_flat_forward(todays_date, rate)\n",
    "\n",
    "    Euribor6M = ql.Euribor6M(flat_forward_relinkable_handle)\n",
    "\n",
    "    # Create simple swap portfolio...\n",
    "    list_of_start_dates = [\n",
    "        todays_date + ql.Period(\"2d\"),\n",
    "        todays_date + ql.Period(\"2d\")\n",
    "    ]\n",
    "\n",
    "    list_of_maturity_dates = [ql.Period(years) for years in [\"5Y\", \"4Y\"]]\n",
    "\n",
    "    list_of_nominal_amounts = [1E6, 5E5]\n",
    "    list_of_float_indices = [Euribor6M, Euribor6M]\n",
    "    list_of_fixed_rates = [0.03, 0.03]\n",
    "\n",
    "    list_of_swap_types = [ql.VanillaSwap.Payer, ql.VanillaSwap.Receiver]\n",
    "\n",
    "    simple_portfolio = make_simple_portfolio(\n",
    "        list_of_start_dates, list_of_maturity_dates,\n",
    "        list_of_nominal_amounts,\n",
    "        list_of_float_indices,\n",
    "        list_of_fixed_rates,\n",
    "        list_of_swap_types\n",
    "    )\n",
    "\n",
    "    portfolio_npv = calculate_portfolio_npv(flat_forward_relinkable_handle, simple_portfolio)\n",
    "\n",
    "    # Instantiate the Gsr model...\n",
    "\n",
    "    volatility_step_dates = [todays_date + 100]\n",
    "\n",
    "    volatilities = [\n",
    "        ql.QuoteHandle(ql.SimpleQuote(0.0075)),\n",
    "        ql.QuoteHandle(ql.SimpleQuote(0.0075))\n",
    "    ]\n",
    "\n",
    "    mean_reversion = [ql.QuoteHandle(ql.SimpleQuote(0.02))]\n",
    "\n",
    "    gsr_model = generate_gsr_model(flat_forward_handle,\n",
    "                                   volatility_step_dates, volatilities,\n",
    "                                   mean_reversion,\n",
    "                                   forward_measure_time=16.0)\n",
    "\n",
    "    # Create evaluation grid and simulate paths (using the Gsr model)...\n",
    "\n",
    "    evaluation_dates_grid, evaluation_time_grid = \\\n",
    "        define_evaluation_grid(todays_date, simple_portfolio)\n",
    "\n",
    "    inv_cumulative_gaussian_rsg = create_random_number_generator(evaluation_time_grid)\n",
    "\n",
    "    number_of_paths = 5000\n",
    "    tenors = np.array([0.0, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "    x, zero_bonds = generate_paths(\n",
    "        number_of_paths, evaluation_time_grid, tenors, inv_cumulative_gaussian_rsg, gsr_model\n",
    "    )\n",
    "\n",
    "    # Plot paths...\n",
    "    # for i in range(number_of_paths):\n",
    "    #     plt.plot(evaluation_time_grid, x[i, :])\n",
    "\n",
    "    # Create the discounted NPV matrix...\n",
    "    npv_matrix = create_npv_matrix(\n",
    "        todays_date,\n",
    "        number_of_paths,\n",
    "        evaluation_dates_grid,\n",
    "        simple_portfolio,\n",
    "        flat_forward,\n",
    "        flat_forward_relinkable_handle,\n",
    "        zero_bonds,\n",
    "        Euribor6M\n",
    "    )\n",
    "\n",
    "    discount_factors = generate_discount_factors(flat_forward_handle, evaluation_time_grid)\n",
    "\n",
    "    discounted_npv_cube = calculate_discounted_npv_matrix(npv_matrix, discount_factors)\n",
    "\n",
    "    # Calculate the portfolio NPV for the netting set...\n",
    "    portfolio_npv = calculate_netted_npv_matrix(npv_matrix)\n",
    "    discounted_portfolio_npv = calculate_netted_npv_matrix(discounted_npv_cube)\n",
    "\n",
    "#     # Plot the first NPV paths...\n",
    "#     n_first, n_last = 0, 30\n",
    "#     plot_npv_paths(n_first, n_last,\n",
    "#                    evaluation_time_grid,\n",
    "#                    portfolio_npv, discounted_portfolio_npv)\n",
    "\n",
    "    # Calculate the exposure and discounted exposure...\n",
    "    exposure = calculate_exposure(portfolio_npv)\n",
    "    discounted_exposure = calculate_exposure(discounted_portfolio_npv)\n",
    "\n",
    "#     # Plot the first exposure paths...\n",
    "#     n_first, n_last = 0, 30\n",
    "#     plot_exposure_paths(n_first, n_last,\n",
    "#                         evaluation_time_grid,\n",
    "#                         exposure, discounted_exposure)\n",
    "#\n",
    "    # Calculate the \"expected\" and the \"expected discounted\" exposure...\n",
    "    expected_exposure = calculate_expected_exposure(portfolio_npv, number_of_paths)\n",
    "    expected_discounted_exposure = calculate_expected_exposure(discounted_portfolio_npv, number_of_paths)\n",
    "\n",
    "#     # Plot the \"expected\" and the \"expected discounted\" exposure paths...\n",
    "#     plot_expected_exposure_paths(evaluation_time_grid,\n",
    "#                                  expected_exposure, expected_discounted_exposure)\n",
    "#\n",
    "#     plot_expected_discounted_exposure(evaluation_time_grid,\n",
    "#                                       expected_discounted_exposure)\n",
    "#\n",
    "    # Calculate the PFE (corresponding to the default 95% quantile)...\n",
    "    potential_future_exposure = \\\n",
    "        calculate_potential_future_exposure(exposure, number_of_paths)\n",
    "\n",
    "#     plot_potential_future_exposure(evaluation_time_grid,\n",
    "#                                    potential_future_exposure)\n",
    "\n",
    "    # calculate the maximum PFE...\n",
    "    max_potential_future_exposure = np.max(potential_future_exposure)\n",
    "\n",
    "    # Default curve\n",
    "    default_dates = [todays_date + ql.Period(i_year, ql.Years) for i_year in range(11)]\n",
    "    hazard_rates = [0.02 * i_year for i_year in range(11)]\n",
    "\n",
    "    default_curve = create_default_curve(default_dates, hazard_rates)\n",
    "\n",
    "#     # Plot default curves (default and survival probabilities, default densities, and hazard rates)...\n",
    "#\n",
    "#     default_times = np.linspace(0, 30, 100)\n",
    "#     plot_default_curve(default_times, default_curve)\n",
    "\n",
    "    # Calculate default probabilities...\n",
    "    default_probabilities = \\\n",
    "        calculate_default_probability_grid(evaluation_time_grid, default_curve)\n",
    "\n",
    "    # Calculation of the CVA...\n",
    "    economic_cva = calculate_economic_cva(expected_discounted_exposure, default_probabilities, recovery_rate=0.4)\n",
    "    print(economic_cva)\n",
    "\n",
    "    # List of TODOs...\n",
    "\n",
    "    # TODO Use QuantLib to calculate CCR and CVA REA, and KVA with SA-CCR\n",
    "    # TODO Add doc tests to functions\n",
    "    # TODO Use pandas to request data and SQLite or MySQL as data repositories\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    time_all = pc()\n",
    "    main()\n",
    "    print(\"xVa pricing time \", pc() - time_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
