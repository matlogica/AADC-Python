{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/matlogica/AADC-Python/blob/main/QuantLib/xVA/xVA-QL-Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AADC enabled C++ QuantLib xVA benchmark\n",
    "\n",
    "\n",
    "### The benchmark is based on xVA example from here:\n",
    "\n",
    "https://raw.githubusercontent.com/carljohanrehn/quantlib-xva/master/quantlib-xva/firstdraft.py\n",
    "\n",
    "== Small change is applied to update to QuantLib version 1.33\n",
    "\n",
    "== Code is modified to perform 5000 MC simulations.\n",
    "\n",
    "== Original code is in xVA-QL-Original.ipynb and it runs in about 35seconds, this version runs in 0.1 seconds AND computes all sensitivities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeBcI8qRteol"
   },
   "source": [
    "This Python module calculates the Credit Value Adjustment for a single netting set of plain vanilla\n",
    "interest rate swaps.\n",
    "\n",
    "The code is based on the IPython Notebook of Matthias Groncki (see reference below).\n",
    "\n",
    "References:\n",
    "\n",
    "\"CVA Calculation with QuantLib and Python\", Matthias Groncki\n",
    "    - https://ipythonquant.wordpress.com/tag/cva/\n",
    "    - http://nbviewer.ipython.org/github/mgroncki/IPythonScripts/blob/master/CVA_calculation_I.ipynb\n",
    "\n",
    "\"FOOLING AROUND WITH QUANTLIB: GSR MODEL\", Peter Caspers:\n",
    "    - https://quantlib.wordpress.com/tag/gsr-model/\n",
    "\n",
    "\"One Factor Gaussian Short Rate Model Implementation\", Peter Caspers, March 1, 2013:\n",
    "    - http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2246013\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFfZYLiUtrlJ"
   },
   "source": [
    "Install AADC enabled QuantLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ng3ma6R8tdsb",
    "outputId": "0ddb15c5-9dea-46ca-8318-1a5f26f89ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: aadc-1.7.5.2401-cp310-cp310-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install https://matlogica.com/DemoReleases/aadc-1.7.5.2401-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "h8DpuwWit3_1",
    "outputId": "5f538b06-5b2c-4e72-b2f7-2acfd78de638"
   },
   "outputs": [],
   "source": [
    "from time import perf_counter as pc\n",
    "\n",
    "import aadc\n",
    "import numpy as np\n",
    "\n",
    "ql = aadc.QuantLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci8X63ZIudIs"
   },
   "source": [
    "## Next code is taken from original sources and unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ue4Cdj6ouH-0"
   },
   "outputs": [],
   "source": [
    "def get_version():\n",
    "    return list(map(int, ql.__version__.split(\".\")))\n",
    "\n",
    "\n",
    "# General QuantLib functions...\n",
    "def set_evaluation_date(date):\n",
    "    ql.Settings.instance().evaluationDate = date\n",
    "\n",
    "def link_to_curve(relinkable_handle, curve):\n",
    "    return relinkable_handle.linkTo(curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O6hDTkW6uLKK"
   },
   "outputs": [],
   "source": [
    "# Random numbers...\n",
    "def create_random_number_generator(evaluation_time_grid, seed=1):\n",
    "    uniform_rng = ql.MersenneTwisterUniformRng(seed)\n",
    "    uniform_rsg = ql.MersenneTwisterUniformRsg(len(evaluation_time_grid) - 1, uniform_rng)\n",
    "\n",
    "    return ql.InvCumulativeMersenneTwisterGaussianRsg(uniform_rsg)\n",
    "\n",
    "\n",
    "# Default curve...\n",
    "def create_default_curve(default_dates, hazard_rates, day_count=ql.Actual365Fixed()):\n",
    "    default_curve = ql.HazardRateCurve(default_dates, hazard_rates, day_count)\n",
    "    default_curve.enableExtrapolation()\n",
    "\n",
    "    return default_curve\n",
    "\n",
    "\n",
    "def get_default_probability(times, default_curve):\n",
    "    # TODO ...\n",
    "    # torch.FloatTensor(default_curve.defaultProbability)\n",
    "\n",
    "    return np.vectorize(default_curve.defaultProbability)(times)\n",
    "\n",
    "\n",
    "def get_survival_probability(times, default_curve):\n",
    "    return np.vectorize(default_curve.survivalProbability)(times)\n",
    "\n",
    "\n",
    "def get_default_density(times, default_curve):\n",
    "    return np.vectorize(default_curve.defaultDensity)(times)\n",
    "\n",
    "\n",
    "def get_hazard_rate(times, default_curve):\n",
    "    \"\"\"\n",
    "\n",
    "    @param times:\n",
    "    @param default_curve:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "\n",
    "    return np.vectorize(default_curve.hazardRate)(times)\n",
    "\n",
    "\n",
    "def calculate_default_probability_grid(evaluation_time_grid, default_curve):\n",
    "    return np.vectorize(default_curve.defaultProbability)(evaluation_time_grid[:-1], evaluation_time_grid[1:])\n",
    "\n",
    "\n",
    "# Discount curve...\n",
    "def create_flat_forward(todays_date, rate, day_count=ql.Actual365Fixed()):\n",
    "    flat_forward = ql.FlatForward(todays_date, ql.QuoteHandle(rate), day_count)\n",
    "    flat_forward.enableExtrapolation()\n",
    "\n",
    "    return flat_forward, ql.YieldTermStructureHandle(flat_forward), ql.RelinkableYieldTermStructureHandle(flat_forward)\n",
    "\n",
    "\n",
    "def generate_discount_factors(flat_forward_handle, evaluation_time_grid):\n",
    "    #    return np.vectorize(flat_forward_handle.discount)(evaluation_time_grid)\n",
    "    return np.vectorize(flat_forward_handle.currentLink().discount)(evaluation_time_grid)\n",
    "\n",
    "\n",
    "def get_discount_curve(curve_dates, discount_factors, day_count_convention=ql.Actual365Fixed()):\n",
    "    discount_curve = ql.DiscountCurve(curve_dates, discount_factors, day_count_convention)\n",
    "\n",
    "    discount_curve.enableExtrapolation()\n",
    "\n",
    "    return discount_curve\n",
    "\n",
    "\n",
    "# Pricing engine...\n",
    "def create_pricing_engine(flat_forward_relinkable_handle):\n",
    "    return ql.DiscountingSwapEngine(flat_forward_relinkable_handle)\n",
    "\n",
    "\n",
    "# Swap portfolio...\n",
    "def create_plain_vanilla_swap(\n",
    "    start_date,\n",
    "    maturity_date,\n",
    "    nominal_amount,\n",
    "    float_index,\n",
    "    fixed_rate,\n",
    "    #                              fixed_leg_tenor=ql.Period(\"1y\"),\n",
    "    fixed_leg_tenor=ql.PeriodParser.parse(\"1y\"),\n",
    "    fixed_leg_business_day_convention=ql.ModifiedFollowing,\n",
    "    fixed_leg_day_count_convention=ql.Thirty360(ql.Thirty360.BondBasis),\n",
    "    calendar=ql.Sweden(),\n",
    "    spread=0.0,\n",
    "    swap_type=ql.VanillaSwap.Payer,\n",
    "):\n",
    "    end_date = calendar.advance(start_date, maturity_date)\n",
    "\n",
    "    fixed_schedule = ql.Schedule(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        fixed_leg_tenor,\n",
    "        float_index.fixingCalendar(),\n",
    "        fixed_leg_business_day_convention,\n",
    "        fixed_leg_business_day_convention,\n",
    "        ql.DateGeneration.Backward,\n",
    "        False,\n",
    "    )\n",
    "\n",
    "    float_schedule = ql.Schedule(\n",
    "        start_date,\n",
    "        end_date,\n",
    "        float_index.tenor(),\n",
    "        float_index.fixingCalendar(),\n",
    "        float_index.businessDayConvention(),\n",
    "        float_index.businessDayConvention(),\n",
    "        ql.DateGeneration.Backward,\n",
    "        False,\n",
    "    )\n",
    "\n",
    "    swap = ql.VanillaSwap(\n",
    "        swap_type,\n",
    "        nominal_amount,\n",
    "        fixed_schedule,\n",
    "        fixed_rate,\n",
    "        fixed_leg_day_count_convention,\n",
    "        float_schedule,\n",
    "        float_index,\n",
    "        spread,\n",
    "        float_index.dayCounter(),\n",
    "    )\n",
    "\n",
    "    return swap, [float_index.fixingDate(x) for x in float_schedule][:-1]\n",
    "\n",
    "\n",
    "def make_simple_portfolio(\n",
    "    list_of_start_dates,\n",
    "    list_of_maturity_dates,\n",
    "    list_of_nominal_amounts,\n",
    "    list_of_float_indices,\n",
    "    list_of_fixed_rates,\n",
    "    list_of_swap_types,\n",
    "):\n",
    "    simple_portfolio = []\n",
    "\n",
    "    for start_date, maturity_date, nominal_amount, float_index, fixed_rate, swap_type in zip(\n",
    "        list_of_start_dates,\n",
    "        list_of_maturity_dates,\n",
    "        list_of_nominal_amounts,\n",
    "        list_of_float_indices,\n",
    "        list_of_fixed_rates,\n",
    "        list_of_swap_types,\n",
    "    ):\n",
    "        simple_portfolio.append(\n",
    "            create_plain_vanilla_swap(\n",
    "                start_date, maturity_date, nominal_amount, float_index, fixed_rate, swap_type=swap_type\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return simple_portfolio\n",
    "\n",
    "\n",
    "def calculate_portfolio_npv(flat_forward_relinkable_handle, portfolio):\n",
    "    engine = create_pricing_engine(flat_forward_relinkable_handle)\n",
    "\n",
    "    portfolio_npv = []\n",
    "    for deal, _ in portfolio:\n",
    "        deal.setPricingEngine(engine)\n",
    "        portfolio_npv.append(deal.NPV())\n",
    "\n",
    "    return portfolio_npv\n",
    "\n",
    "\n",
    "# Evaluation grid, curve dates, and NPV matrix...\n",
    "def define_evaluation_grid(todays_date, simple_portfolio, number_of_months=12 * 6):\n",
    "    evaluation_dates_grid = [todays_date + ql.Period(i_month, ql.Months) for i_month in range(number_of_months)]\n",
    "\n",
    "    for deal in simple_portfolio:\n",
    "        evaluation_dates_grid += deal[1]\n",
    "\n",
    "    evaluation_dates_grid = np.unique(np.sort(evaluation_dates_grid))\n",
    "\n",
    "    evaluation_time_grid = np.vectorize(\n",
    "        lambda x: ql.ActualActual(ql.ActualActual.ISDA).yearFraction(\n",
    "            todays_date, x\n",
    "        )  # empty constructor doesn't exist???\n",
    "    )(evaluation_dates_grid)\n",
    "\n",
    "    # diff_evaluation_time_grid = evaluation_time_grid[1:] - evaluation_time_grid[:-1]\n",
    "\n",
    "    return evaluation_dates_grid, evaluation_time_grid  # , diff_evaluation_time_grid\n",
    "\n",
    "\n",
    "def define_curve_dates(date, n_years=10):\n",
    "    # append first half year to date\n",
    "    curve_dates = [date, date + ql.Period(6, ql.Months)]\n",
    "\n",
    "    curve_dates += [date + ql.Period(i_year, ql.Years) for i_year in range(1, n_years + 1)]\n",
    "\n",
    "    return curve_dates\n",
    "\n",
    "\n",
    "# TODO ...\n",
    "def create_npv_matrix(\n",
    "    todays_date,\n",
    "    number_of_paths,\n",
    "    evaluation_dates_grid,\n",
    "    simple_portfolio,\n",
    "    flat_forward,\n",
    "    flat_forward_relinkable_handle,\n",
    "    zero_bonds,\n",
    "    float_index,\n",
    "):\n",
    "    n_dates, n_deals = len(evaluation_dates_grid), len(simple_portfolio)\n",
    "\n",
    "    npv_matrix = np.zeros((number_of_paths, n_dates, n_deals))\n",
    "\n",
    "    for i_path in range(number_of_paths):\n",
    "        print(\"pricing \", i_path)\n",
    "        for i_date in range(n_dates):\n",
    "            date = evaluation_dates_grid[i_date]\n",
    "\n",
    "            discount_curve = get_discount_curve(define_curve_dates(date), zero_bonds[i_path, i_date, :])\n",
    "\n",
    "            #            set_evaluation_date(date)\n",
    "            ql.Settings().evaluationDate = date\n",
    "            link_to_curve(flat_forward_relinkable_handle, discount_curve)\n",
    "\n",
    "            # TODO Check... is this correct?\n",
    "            is_valid_fixing_date = float_index.isValidFixingDate(date)\n",
    "\n",
    "            if is_valid_fixing_date:\n",
    "                fixing = float_index.fixing(date)\n",
    "                float_index.addFixing(date, fixing)\n",
    "\n",
    "            for i_deal in range(n_deals):\n",
    "                npv_matrix[i_path, i_date, i_deal] = simple_portfolio[i_deal][0].NPV()\n",
    "\n",
    "        ql.IndexManager.instance().clearHistories()\n",
    "\n",
    "    set_evaluation_date(todays_date)\n",
    "    link_to_curve(flat_forward_relinkable_handle, flat_forward)\n",
    "\n",
    "    return npv_matrix\n",
    "\n",
    "\n",
    "def calculate_discounted_npv_matrix(npv_matrix, discount_factors):\n",
    "    discounted_npv_matrix = np.zeros(npv_matrix.shape)\n",
    "\n",
    "    for i in range(npv_matrix.shape[2]):\n",
    "        discounted_npv_matrix[:, :, i] = npv_matrix[:, :, i] * discount_factors\n",
    "\n",
    "    return discounted_npv_matrix\n",
    "\n",
    "\n",
    "# Gsr model and simulation of paths...\n",
    "def generate_gsr_model(\n",
    "    flat_forward_handle, volatility_step_dates, volatilities, mean_reversion, forward_measure_time=16.0\n",
    "):\n",
    "    return ql.Gsr(flat_forward_handle, volatility_step_dates, volatilities, mean_reversion, forward_measure_time)\n",
    "\n",
    "\n",
    "def generate_paths(number_of_paths, evaluation_time_grid, tenors, inv_cumulative_gaussian_rsg, model):\n",
    "    n_tenors = len(tenors)\n",
    "\n",
    "    diff_evaluation_time_grid = evaluation_time_grid[1:] - evaluation_time_grid[:-1]\n",
    "\n",
    "    x = np.zeros((number_of_paths, len(evaluation_time_grid)))\n",
    "    y = np.zeros((number_of_paths, len(evaluation_time_grid)))\n",
    "\n",
    "    zero_bonds = np.zeros((number_of_paths, len(evaluation_time_grid), n_tenors))\n",
    "\n",
    "    for j_tenor in range(n_tenors):\n",
    "        zero_bonds[:, 0, j_tenor] = model.zerobond(tenors[j_tenor], 0, 0)\n",
    "\n",
    "    process = model.stateProcess()\n",
    "\n",
    "    for n_path in range(number_of_paths):\n",
    "        print(\"model path \", n_path)\n",
    "\n",
    "        next_sequence = inv_cumulative_gaussian_rsg.nextSequence().value  # value() is exteded from swig layer\n",
    "\n",
    "        next_sequence_arg = [x.mark_as_input_no_diff() for x in next_sequence]\n",
    "\n",
    "        for i_time in range(1, len(evaluation_time_grid)):\n",
    "            t_start = evaluation_time_grid[i_time - 1]\n",
    "            t_end = evaluation_time_grid[i_time]\n",
    "\n",
    "            x[n_path, i_time] = process.expectation(\n",
    "                t_start, x[n_path, i_time - 1], diff_evaluation_time_grid[i_time - 1]\n",
    "            ) + next_sequence[i_time - 1] * process.stdDeviation(\n",
    "                t_start, x[n_path, i_time - 1], diff_evaluation_time_grid[i_time - 1]\n",
    "            )\n",
    "\n",
    "            # y equals standardized x (see Gsr-paper by Caspers and Gsr model in QuantLib)\n",
    "            y[n_path, i_time] = (x[n_path, i_time] - process.expectation(0, 0, t_end)) / process.stdDeviation(\n",
    "                0, 0, t_end\n",
    "            )\n",
    "\n",
    "            for j_tenor in range(n_tenors):\n",
    "                zero_bonds[n_path, i_time, j_tenor] = model.zerobond(t_end + tenors[j_tenor], t_end, y[n_path, i_time])\n",
    "\n",
    "    return x, zero_bonds, next_sequence_arg\n",
    "\n",
    "\n",
    "# Netting, exposure, and CVA...\n",
    "def calculate_netted_npv_matrix(npv_matrix):\n",
    "    return np.sum(npv_matrix, axis=2)\n",
    "\n",
    "\n",
    "def calculate_exposure(portfolio_npv):\n",
    "    if aadc.is_recording():\n",
    "        exposure = portfolio_npv.copy()\n",
    "        for i in range(len(exposure)):\n",
    "            for j in range(len(exposure[i])):\n",
    "                exposure[i][j] = aadc.math.max(exposure[i][j], 0.0)\n",
    "        return exposure\n",
    "    #    exposure = portfolio_npv.copy()\n",
    "    #    exposure[exposure < 0] = 0\n",
    "    zeros = np.zeros(portfolio_npv.shape)\n",
    "    exposure = np.maximum(portfolio_npv, zeros)\n",
    "\n",
    "    return exposure\n",
    "\n",
    "\n",
    "def calculate_expected_exposure(portfolio_npv, number_of_paths):\n",
    "    return np.sum(calculate_exposure(portfolio_npv), axis=1) / number_of_paths\n",
    "\n",
    "\n",
    "def calculate_potential_future_exposure(exposure, number_of_paths, quantile=0.95):\n",
    "    # TODO Should we have ceil here?\n",
    "    potential_future_exposure = np.apply_along_axis(\n",
    "        lambda x: np.sort(x)[int(np.ceil(quantile * number_of_paths))], 0, exposure\n",
    "    )\n",
    "\n",
    "    # Alternative formulation: use max of each exposure path\n",
    "    # potential_future_exposure = np.sort(np.max(exposure, axis=1))[quantile * number_of_paths]\n",
    "\n",
    "    return potential_future_exposure\n",
    "\n",
    "\n",
    "def calculate_economic_cva(expected_discounted_exposure, default_probabilities, recovery_rate=0.4):\n",
    "    return (1 - recovery_rate) * np.sum(expected_discounted_exposure[1:] * default_probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YwVLFucuyoc"
   },
   "source": [
    "# Next we initialize recording of 1 MonteCarlo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IWMtUx2xvSNN"
   },
   "outputs": [],
   "source": [
    "    # Set evaluation date...\n",
    "    # todays_date = ql.Date(7, 4, 2015)\n",
    "    todays_date = ql.Date(13, 8, 2015)\n",
    "    # ql.Settings.instance().setEvaluationDate(todays_date)\n",
    "    set_evaluation_date(todays_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AADC overrides help with numpy compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aadc.overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7nDTq1PXvWjD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using evaluation version of AADC. Expire date is 20240901\n"
     ]
    }
   ],
   "source": [
    "    funcs = aadc.Functions()\n",
    "    funcs.start_recording()\n",
    "    ctx = aadc.overrides.aadc_overrides()\n",
    "    ctx.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x7D-hLd0vafU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idouble([AAD[rv] [adj] :8,3.00e-02])\n",
      "idouble([AAD[rv] [adj] :8,7.41e-01])\n"
     ]
    }
   ],
   "source": [
    "    # Market data...\n",
    "    rate_value = aadc.idouble(0.03)\n",
    "    rate_arg = rate_value.mark_as_input()\n",
    "\n",
    "    rate = ql.SimpleQuote(rate_value)\n",
    "\n",
    "    flat_forward, flat_forward_handle, flat_forward_relinkable_handle = create_flat_forward(todays_date, rate)\n",
    "\n",
    "    print(rate.value())\n",
    "    print(flat_forward.discount(10))\n",
    "\n",
    "    euribor6m = ql.Euribor6M(flat_forward_relinkable_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Yyt2t34gvnkc"
   },
   "outputs": [],
   "source": [
    "    # Create simple swap portfolio...\n",
    "    list_of_start_dates = [todays_date + ql.PeriodParser.parse(\"2d\"), todays_date + ql.PeriodParser.parse(\"2d\")]\n",
    "\n",
    "    list_of_maturity_dates = [ql.PeriodParser.parse(years) for years in [\"5Y\", \"4Y\"]]\n",
    "\n",
    "    list_of_nominal_amounts = [1e6, 5e5]\n",
    "    list_of_float_indices = [euribor6m, euribor6m]\n",
    "    list_of_fixed_rates = [0.03, 0.03]\n",
    "\n",
    "    list_of_swap_types = [ql.VanillaSwap.Payer, ql.VanillaSwap.Receiver]\n",
    "\n",
    "    simple_portfolio = make_simple_portfolio(\n",
    "        list_of_start_dates,\n",
    "        list_of_maturity_dates,\n",
    "        list_of_nominal_amounts,\n",
    "        list_of_float_indices,\n",
    "        list_of_fixed_rates,\n",
    "        list_of_swap_types,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iGGCGTe-vtEc"
   },
   "outputs": [],
   "source": [
    "    portfolio_npv = calculate_portfolio_npv(flat_forward_relinkable_handle, simple_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3QAoEJxDv1Ak"
   },
   "outputs": [],
   "source": [
    "    # Instantiate the Gsr model...\n",
    "\n",
    "    volatility_step_dates = [todays_date + 100]\n",
    "\n",
    "    ivolatilities = [0.0075, 0.0075]\n",
    "    ivolatilities = [aadc.idouble(x) for x in ivolatilities]\n",
    "    volatilities_arg = [x.mark_as_input() for x in ivolatilities]\n",
    "    volatilities = [ql.QuoteHandle(ql.SimpleQuote(x)) for x in ivolatilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ivKjDD-hv7PV"
   },
   "outputs": [],
   "source": [
    "    mean_reversion = [ql.QuoteHandle(ql.SimpleQuote(0.02))]\n",
    "    #    mean_reversion = [ql.QuoteHandle(ql.SimpleQuote(0.02))]\n",
    "\n",
    "    gsr_model = generate_gsr_model(\n",
    "        flat_forward_handle, volatility_step_dates, volatilities, mean_reversion, forward_measure_time=16.0\n",
    "    )\n",
    "\n",
    "    # Create evaluation grid and simulate paths (using the Gsr model)...\n",
    "\n",
    "    evaluation_dates_grid, evaluation_time_grid = define_evaluation_grid(todays_date, simple_portfolio)\n",
    "\n",
    "    inv_cumulative_gaussian_rsg = create_random_number_generator(evaluation_time_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsRm1rGbv-PN"
   },
   "source": [
    "### Unlike original code, here we set number of paths to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NJpxBQe4wKxN"
   },
   "outputs": [],
   "source": [
    "    number_of_paths = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8JRSm2J6wPsN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path  0\n"
     ]
    }
   ],
   "source": [
    "    tenors = np.array([0.0, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "    x, zero_bonds, next_sequence_arg = generate_paths(\n",
    "        number_of_paths, evaluation_time_grid, tenors, inv_cumulative_gaussian_rsg, gsr_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L8kwrZ17ywSZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pricing  0\n"
     ]
    }
   ],
   "source": [
    "    # Create the discounted NPV matrix...\n",
    "    npv_matrix = create_npv_matrix(\n",
    "        todays_date,\n",
    "        number_of_paths,\n",
    "        evaluation_dates_grid,\n",
    "        simple_portfolio,\n",
    "        flat_forward,\n",
    "        flat_forward_relinkable_handle,\n",
    "        zero_bonds,\n",
    "        euribor6m,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    discount_factors = generate_discount_factors(flat_forward_handle, evaluation_time_grid)\n",
    "\n",
    "    discounted_npv_cube = calculate_discounted_npv_matrix(npv_matrix, discount_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aadc.array([idouble([AAD[rv] [adj] :224,1.24e+03]),\n",
      "       idouble([AAD[rv] [adj] :4348,-6.01e+01]),\n",
      "       idouble([AAD[rv] [adj] :6692,1.40e+04]),\n",
      "       idouble([AAD[rv] [adj] :6671,1.68e+04]),\n",
      "       idouble([AAD[rv] [adj] :6699,2.41e+04]),\n",
      "       idouble([AAD[rv] [adj] :1475,5.15e+03]),\n",
      "       idouble([AAD[rv] [adj] :1458,-7.34e+02]),\n",
      "       idouble([AAD[rv] [adj] :1477,-1.51e+03]),\n",
      "       idouble([AAD[rv] [adj] :5785,1.04e+04]),\n",
      "       idouble([AAD[rv] [adj] :5766,-9.13e+03])], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "    portfolio_npv = calculate_netted_npv_matrix(npv_matrix)\n",
    "    discounted_portfolio_npv = calculate_netted_npv_matrix(discounted_npv_cube)\n",
    "\n",
    "    print(discounted_portfolio_npv[0][range(0,10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    exposure = calculate_exposure(portfolio_npv)\n",
    "    discounted_exposure = calculate_exposure(discounted_portfolio_npv)\n",
    "    discounted_neg_exposure = calculate_exposure(-discounted_portfolio_npv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    default_dates = [todays_date + ql.Period(i_year, ql.Years) for i_year in range(11)]\n",
    "    hazard_rates = [aadc.idouble(0.02 * i_year) for i_year in range(11)]\n",
    "    hazard_rates_arg = [x.mark_as_input() for x in hazard_rates]\n",
    "\n",
    "    default_curve = create_default_curve(default_dates, hazard_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate default probabilities...\n",
    "    default_probabilities = calculate_default_probability_grid(evaluation_time_grid, default_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if aadc.is_recording():\n",
    "        discounted_exposure = discounted_exposure[0]\n",
    "        discounted_neg_exposure = discounted_neg_exposure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idouble([AAD[rv] [adj] :4897,8.20e+01])\n",
      "idouble([AAD[rv] [adj] :6770,1.68e+03])\n"
     ]
    }
   ],
   "source": [
    "    # Calculation of the CVA...\n",
    "    economic_cva = calculate_economic_cva(discounted_exposure, default_probabilities, recovery_rate=0.4)\n",
    "    economic_dva = calculate_economic_cva(discounted_neg_exposure, default_probabilities, recovery_rate=0.4)\n",
    "    print(economic_cva)\n",
    "    print(economic_dva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    portfolio_npv_res = [\n",
    "        aadc.idouble(x).mark_as_output() for x in portfolio_npv[0]\n",
    "    ]  # path 0  some elements are zero floats => aadc.idouble(x)\n",
    "    discounted_portfolio_npv_res = [x.mark_as_output() for x in discounted_portfolio_npv[0]]\n",
    "    economic_cva_res = economic_cva.mark_as_output()\n",
    "    economic_dva_res = economic_dva.mark_as_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.__exit__(None, None, None)\n",
    "funcs.stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next command checks for recording consistency. If number of active to passive conversions is zero, we didn't miss any branches and can use Kernel with arbitrary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number active to passive conversions: 0 while recording Python\n"
     ]
    }
   ],
   "source": [
    "    funcs.print_passive_extract_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command can be used to get Kernel statistics\n",
    "#    print(funcs.recording_stats(\"Python\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AADC Kernel is recorded and can be used to process multiple simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    number_of_paths = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set inputs. Note that market data is scalar, but can be np arrays to process multiple scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    inputs = {}\n",
    "    inputs[rate_arg] = rate_value\n",
    "    for i in range(len(volatilities)):\n",
    "        inputs[volatilities_arg[i]] = ivolatilities[i]\n",
    "    for i in range(len(hazard_rates)):\n",
    "        inputs[hazard_rates_arg[i]] = hazard_rates[i]\n",
    "    randoms = np.zeros((number_of_paths, len(next_sequence_arg)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate all necessary random numbers. This step can be further optimized or cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating randoms...\n",
      "randoms generation time =  0.7078009992837906\n"
     ]
    }
   ],
   "source": [
    "    # create new random generator\n",
    "    print(\"Generating randoms...\")\n",
    "    time_rngen = pc()\n",
    "    inv_cumulative_gaussian_rsg = create_random_number_generator(evaluation_time_grid)\n",
    "    #    inv_cumulative_gaussian_rsg.nextSequence()\n",
    "    for i in range(number_of_paths):\n",
    "        next_sequence = inv_cumulative_gaussian_rsg.nextSequence().value\n",
    "        randoms[i, :] = next_sequence\n",
    "\n",
    "    for i in range(len(next_sequence_arg)):\n",
    "        inputs[next_sequence_arg[i]] = randoms[:, i]\n",
    "\n",
    "    print(\"randoms generation time = \", pc() - time_rngen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare request object. Here we want cva/dva values and their sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    request = {\n",
    "        economic_cva_res: [rate_arg] + volatilities_arg + hazard_rates_arg,\n",
    "        economic_dva_res: [rate_arg] + volatilities_arg + hazard_rates_arg,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also want to get portfolio values to calculate Expected Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(len(discounted_portfolio_npv_res)):\n",
    "        request[discounted_portfolio_npv_res[i]] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running simulations. Here we use avx2 and 1 CPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation...\n",
      "evaluation time =  0.5532950637862086\n"
     ]
    }
   ],
   "source": [
    "    print(\"Running simulation...\")\n",
    "    t0 = pc()\n",
    "    results = aadc.evaluate(funcs, request, inputs, aadc.ThreadPool(1))\n",
    "    print(\"evaluation time = \", pc() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare this with using 4 CPU cores. Note that QL isn't MT safe, but AADC Kernels are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation...\n",
      "evaluation time =  0.1551763121969998\n"
     ]
    }
   ],
   "source": [
    "    print(\"Running simulation...\")\n",
    "    t0 = pc()\n",
    "    results = aadc.evaluate(funcs, request, inputs, aadc.ThreadPool(4))\n",
    "    print(\"evaluation time = \", pc() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVA: 627.5282798805566\n",
      "DVA: 1502.2034089410563\n"
     ]
    }
   ],
   "source": [
    "    print(\"CVA:\", np.average(results[0][economic_cva_res]))\n",
    "    print(\"DVA:\", np.average(results[0][economic_dva_res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dCVA/dVol[ 0 ]: 10692.44526851851\n",
      "dCVA/dVol[ 1 ]: 68994.5232733822\n",
      "dCVA/dHazR[ 0 ]: 0.0\n",
      "dCVA/dHazR[ 1 ]: 1531.2324739295902\n",
      "dCVA/dHazR[ 2 ]: 2609.7167390061313\n",
      "dCVA/dHazR[ 3 ]: 2544.7505994528397\n",
      "dCVA/dHazR[ 4 ]: 2062.380204309356\n",
      "dCVA/dHazR[ 5 ]: 1034.595318397354\n",
      "dCVA/dHazR[ 6 ]: 0.0\n",
      "dCVA/dHazR[ 7 ]: 0.0\n",
      "dCVA/dHazR[ 8 ]: 0.0\n",
      "dCVA/dHazR[ 9 ]: 0.0\n",
      "dCVA/dHazR[ 10 ]: 0.0\n"
     ]
    }
   ],
   "source": [
    "    for i in range(len(volatilities_arg)):\n",
    "        print(\"dCVA/dVol[\", i, \"]:\", np.average(results[1][economic_cva_res][volatilities_arg[i]]))\n",
    "    for i in range(len(hazard_rates_arg)):\n",
    "        print(\"dCVA/dHazR[\", i, \"]:\", np.average(results[1][economic_cva_res][hazard_rates_arg[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aadc_discounted_portfolio_npv = np.zeros((len(discounted_portfolio_npv_res), number_of_paths))\n",
    "for i in range(len(discounted_portfolio_npv_res)):\n",
    "    aadc_discounted_portfolio_npv[i] = results[0][discounted_portfolio_npv_res[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    expected_exposure = calculate_expected_exposure(portfolio_npv, number_of_paths)\n",
    "expected_discounted_exposure = calculate_expected_exposure(aadc_discounted_portfolio_npv, number_of_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1235.9067555 ,  1235.9067555 ,  1235.9067555 , ...,\n",
       "         1235.9067555 ,  1235.9067555 ,  1235.9067555 ],\n",
       "       [  -60.13707245,  4527.14675854,  4572.4976872 , ...,\n",
       "        -1305.46106792, -1068.8169734 , -2284.38335432],\n",
       "       [13962.75337849,  1730.42322898,  2569.48500942, ...,\n",
       "         1973.50273763, 10186.28232247, -8867.3034623 ],\n",
       "       ...,\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ],\n",
       "       [    0.        ,     0.        ,     0.        , ...,\n",
       "            0.        ,     0.        ,     0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aadc_discounted_portfolio_npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we use prerecorded Kernel to calculate CVA/DVA and risk for arbitrary shocks in input Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalc(rate_shift):\n",
    "    inputs[rate_arg] = rate_value+rate_shift/100\n",
    "    t0 = pc()\n",
    "    results = aadc.evaluate(funcs, request, inputs, aadc.ThreadPool(10))\n",
    "    print(\"evaluation time = \", pc() - t0, \"sec\")\n",
    "    for i in range(len(discounted_portfolio_npv_res)):\n",
    "        aadc_discounted_portfolio_npv[i] = results[0][discounted_portfolio_npv_res[i]]\n",
    "    expected_discounted_exposure = calculate_expected_exposure(aadc_discounted_portfolio_npv, number_of_paths)\n",
    "\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(evaluation_time_grid, expected_discounted_exposure)\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.ylabel(\"PFE\")\n",
    "\n",
    "    cva_hazard_rates_delta = np.zeros(np.shape(hazard_rates_arg))\n",
    "    for i in range(len(hazard_rates_arg)):\n",
    "        cva_hazard_rates_delta[i] = np.average(results[1][economic_cva_res][hazard_rates_arg[i]])\n",
    "    dva_hazard_rates_delta = np.zeros(np.shape(hazard_rates_arg))\n",
    "    for i in range(len(hazard_rates_arg)):\n",
    "        dva_hazard_rates_delta[i] = np.average(results[1][economic_dva_res][hazard_rates_arg[i]])\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.bar(list(range(len(hazard_rates_arg))), cva_hazard_rates_delta)\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.ylabel(\"dCVA\")\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.bar(list(range(len(hazard_rates_arg))), dva_hazard_rates_delta)\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.ylabel(\"dDVA\")\n",
    "\n",
    "    print(\"CVA:\", np.average(results[0][economic_cva_res]))\n",
    "    print(\"DVA:\", np.average(results[0][economic_dva_res]))\n",
    "    \n",
    "\n",
    "widgets.interact(recalc, rate_shift=(-5, 10, 0.00005))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
